# -*- coding: utf-8 -*-
"""yolo_filter.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SNKnk3JGrEDtRnwSK2X9T_L5hhot9kSg

## **Yolo_Filter**
"""

import os
import cv2
import time
from ultralytics import YOLO
from tqdm import tqdm

class Config:
    # Path configurations
    VIDEO_PATH = "/content/task_video.mp4"
    OUTPUT_DIR = "/content/drive/MyDrive/Colab Notebooks"
    NEW_DATASET_DIR = os.path.join(OUTPUT_DIR, "new_dataset")
    MODEL_PATH = "/content/yolov8n.pt"

    # Detection parameters
    CONFIDENCE_THRESH = 0.3
    IOU_THRESH = 0.5

    # Class settings
    VEHICLE_CLASSES = ['car', 'bus', 'truck', 'motorcycle', 'bicycle']
    PERSON_CLASS = 'person'

    # Delay (in seconds) after processing each frame to give the model more time
    FRAME_PROCESSING_DELAY = 0.1

def process_detections(results, vehicle_classes):
    """Process YOLO results and separate vehicles/persons."""
    vehicles = []
    persons = []
    detections = []

    for result in results:
        for box in result.boxes:
            if box.conf < Config.CONFIDENCE_THRESH:
                continue

            x1, y1, x2, y2 = map(int, box.xyxy[0])
            cls_id = int(box.cls)
            cls_name = result.names[cls_id]

            if cls_name in vehicle_classes:
                vehicles.append((x1, y1, x2, y2))
                detections.append((cls_id, x1, y1, x2, y2))
            elif cls_name == Config.PERSON_CLASS:
                persons.append((x1, y1, x2, y2))

    return vehicles, persons, detections

def filter_persons(persons, vehicles, person_cls_id):

    filtered = []
    for (x1, y1, x2, y2) in persons:
        center_x = (x1 + x2) / 2.0
        center_y = (y1 + y2) / 2.0
        inside = False
        for (vx1, vy1, vx2, vy2) in vehicles:
            if vx1 <= center_x <= vx2 and vy1 <= center_y <= vy2:
                inside = True
                break
        if not inside:
            filtered.append((person_cls_id, x1, y1, x2, y2))
    return filtered

def run_object_detection():
    # Initialize model and video
    model = YOLO(Config.MODEL_PATH)
    cap = cv2.VideoCapture(Config.VIDEO_PATH)

    # Get the class id for the person class
    person_cls_id = None
    for cls_id, name in model.names.items():
        if name == Config.PERSON_CLASS:
            person_cls_id = cls_id
            break
    if person_cls_id is None:
        raise ValueError("Person class not found in model")

    # Create new dataset directory and its subdirectories
    os.makedirs(Config.NEW_DATASET_DIR, exist_ok=True)
    img_dir = os.path.join(Config.NEW_DATASET_DIR, "images")
    label_dir = os.path.join(Config.NEW_DATASET_DIR, "labels")
    os.makedirs(img_dir, exist_ok=True)
    os.makedirs(label_dir, exist_ok=True)

    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    with tqdm(total=total_frames, desc="Processing video") as pbar:
        frame_count = 0
        while cap.isOpened():
            success, frame = cap.read()
            if not success:
                break

            # Run object detection on the frame
            results = model(frame, conf=Config.CONFIDENCE_THRESH,
                           iou=Config.IOU_THRESH, verbose=False)

            # Process detections: separate vehicles and persons
            vehicles, persons, detections = process_detections(results, Config.VEHICLE_CLASSES)

            # Filter out persons that are inside a detected vehicle
            filtered_persons = filter_persons(persons, vehicles, person_cls_id)
            final_detections = detections + filtered_persons

            # YOLO format
            height, width = frame.shape[:2]
            img_path = os.path.join(img_dir, f"{frame_count:04d}.jpg")
            label_path = os.path.join(label_dir, f"{frame_count:04d}.txt")

            cv2.imwrite(img_path, frame)

            with open(label_path, "w") as f:
                for detection in final_detections:
                    cls_id, x1, y1, x2, y2 = detection
                    x_center = (x1 + x2) / (2.0 * width)
                    y_center = (y1 + y2) / (2.0 * height)
                    w = (x2 - x1) / width
                    h = (y2 - y1) / height
                    f.write(f"{cls_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\n")

            frame_count += 1
            pbar.update(1)

            # Adding a short delay to ensure each frame is processed properly
            time.sleep(Config.FRAME_PROCESSING_DELAY)

    cap.release()
    print(f"Results saved in {Config.NEW_DATASET_DIR}")

if __name__ == "__main__":
    run_object_detection()